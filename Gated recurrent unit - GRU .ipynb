{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highlights\n",
    "* Varient of LSTM\n",
    "* Retains the resistance to vanishinig gradient problem\n",
    "* Simple internal structure\n",
    "* Trains faster\n",
    "* Fewer computation required for update hidden states\n",
    "* LSTM in theory remember longer sequences than GRU & outperform them requiring model long-distance relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gates Information - LSTM have input, forget & output gate, GRU have update gate & reset gate\n",
    "\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/deep-learning-with/9781787128422/assets/gru-cell.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.safaribooksonline.com/library/view/deep-learning-with/9781787128422/assets/gru-eq1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seq: 25000\n",
      "Test seq: 25000\n"
     ]
    }
   ],
   "source": [
    "n_words = 1000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=n_words)\n",
    "print('Train seq: {}'.format(len(X_train)))\n",
    "print('Test seq: {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pad sequence with max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4, 807,   9,   2,   2,  19,   2,   2, 411,   5,   2,  34,   2,\n",
       "       156,  37, 481,  40,  68, 886,   6, 229,  18,   4,  86,  58,   4,\n",
       "         2,   2,  22, 405,   9,   6, 706,   2,   7,   4,   4,   2, 405,\n",
       "         2, 302,   4, 105,  81,  24,  60, 511,  40,   6,   2, 415,  62,\n",
       "        18, 463,   4, 109,  37,   9, 267,  18,  41,   2, 799,  33,  41,\n",
       "       344,   2,  41,  96, 143,   4,   2,   2,   2, 187,   4, 313,  32,\n",
       "         2,   5,   2,   5,  59, 152,  60, 280, 683,  46,  41,   2, 403,\n",
       "         8,  67,  48,  59,   9, 344,  51,  25,  62, 104,  59,  69,  43,\n",
       "         2,  41, 799, 305,   7,   2,  18,  41,  96,  99, 111,   2,   8,\n",
       "        41,   2,  99, 111,   2,   2,   9,   6, 801,   2,   7,  35,   2,\n",
       "       167,  12,   9, 165, 163, 149,   4,   2, 665,   7,   4, 255,   2,\n",
       "        41, 519, 180,   4, 890,  56,   4,   2, 187,  14,   2, 120, 133,\n",
       "       120,  50, 449,   6, 499, 650, 150,   6,   2, 650, 195, 460,  25,\n",
       "        62, 104,  25,  26, 149,   6, 248,   2,  18,   4,   2, 394,  20,\n",
       "         2,  46,   7,   2,  13,  66,   2,   2,  37,   2, 278, 231,  14,\n",
       "        22,  42,   8, 106,  12])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200, 50)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 100)               45300     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               25250     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 120,801\n",
      "Trainable params: 120,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define network architecture and compile\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_words, 50, input_length=max_len))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 312s 16ms/step - loss: 0.6706 - acc: 0.5758 - val_loss: 0.5749 - val_acc: 0.6926\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 324s 16ms/step - loss: 0.5324 - acc: 0.7344 - val_loss: 0.5180 - val_acc: 0.7372\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 361s 18ms/step - loss: 0.4767 - acc: 0.7744 - val_loss: 0.4768 - val_acc: 0.7670\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 412s 21ms/step - loss: 0.4551 - acc: 0.7898 - val_loss: 0.4569 - val_acc: 0.7846\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 415s 21ms/step - loss: 0.4446 - acc: 0.8014 - val_loss: 0.4500 - val_acc: 0.7830\n",
      "Epoch 6/100\n",
      " 2560/20000 [==>...........................] - ETA: 5:46 - loss: 0.4341 - acc: 0.8172"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 512\n",
    "n_epochs = 100\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
